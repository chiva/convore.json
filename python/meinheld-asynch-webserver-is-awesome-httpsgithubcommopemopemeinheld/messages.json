[{"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304191658.577493, "message": "Just doing simple benchmarks with ab, running gunicorn --workers=2 --worker-class=\"egg:meinheld#gunicorn_worker\" gunicorn_test:app and I'm getting 20k requests/sec vs 6-7k w/o meinheld.", "group_id": 292, "id": 871078}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304191626.8403151, "message": "Tons of really neat features, integrates with django/gunicorn/flask very well.", "group_id": 292, "id": 871076}, {"user_id": 6415, "stars": [], "topic_id": 32965, "date_created": 1304193393.0926299, "message": "Have you tried with nginx proxing requests to gunicorn? This is the recommended configuration for the synchronous version of gunicorn.", "group_id": 292, "id": 871310}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304194274.1791711, "message": "I actually wasn't testing them behind nginx. They bench a lot slower when proxied to from nginx, unsurprisingly, although meinheld is still a lot faster than the synch version of gunicorn. I'm fairly sure I can tune my nginx settings a bit, but I'm getting about 12k req/s vs 5-6 k req/s with nginx in front.", "group_id": 292, "id": 871472}, {"user_id": 6415, "stars": [], "topic_id": 32965, "date_created": 1304197230.542851, "message": "meinheld doesn't require nginx although you may want to use it to serve static files. The synch version of gunicorn should be faster proxied by nginx than without. Is that what you get with the sync version: 12k req/s with nginx and 5-6k req/s without? Or is it the opposite?", "group_id": 292, "id": 871935}, {"user_id": 19761, "stars": [{"date_created": 1304199166.121402, "user_id": 6415}], "topic_id": 32965, "date_created": 1304198251.3733151, "message": "I meant meinheld worker gets 12k req/s behind nginx, synch get's around 5-6k req/s. Using a gevent worker is in-between that for me, around 7-8k req/s", "group_id": 292, "id": 872163}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304202043.9507079, "message": "interestingly with keep-alives meinheld even out-performed uwsgi by a large margin", "group_id": 292, "id": 872744}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304201624.8316231, "message": "http://paste.pound-python.org/show/5932/ here are the actual results as well as my nginx.conf and the test wsgi application. I went ahead and threw uwsgi in there as well. Pretty amazed at gunicorn's performance actually.", "group_id": 292, "id": 872699}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304201698.8557119, "message": "uWSGI 0.9.7.2, gevent 0.13.5", "group_id": 292, "id": 872705}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304202063.0749331, "message": "http://paste.pound-python.org/show/5933/ 20,000 req/s for meinheld vs 14,000 req/s with uwsgi", "group_id": 292, "id": 872746}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304202084.9363999, "message": "using only two workers vs 8 processes!", "group_id": 292, "id": 872748}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304202258.733629, "message": "seems pretty awesome for light-weight services, gunicorn w/meinheld workers using very small amounts of memory", "group_id": 292, "id": 872753}, {"user_id": 6415, "stars": [], "topic_id": 32965, "date_created": 1304203428.317898, "message": "Yes, serving \"hello world\" is very light-weight service indeed :)", "group_id": 292, "id": 872845}, {"user_id": 6415, "stars": [], "topic_id": 32965, "date_created": 1304203561.9693949, "message": "Having some I/O in the process would make a more interesting test to compare sync vs async servers IMO.", "group_id": 292, "id": 872850}, {"user_id": 19761, "stars": [], "topic_id": 32965, "date_created": 1304206285.9767139, "message": "Also tested at higher concurrency levels, with interesting results. 500 and 1000 concurrency. http://paste.pound-python.org/show/5937/. My system isn't really tuned for high concurrency stuff. Meinheld has a continuation api for async programming. I'll have to spend some time with it, but I'm really impressed with it.", "group_id": 292, "id": 873111}, {"user_id": 31830, "stars": [{"date_created": 1304227335.2051749, "user_id": 1}, {"date_created": 1304232975.6980121, "user_id": 6671}, {"date_created": 1304283037.979691, "user_id": 6415}], "topic_id": 32965, "date_created": 1304226481.2366121, "message": "please, choose your app container using other metrics. Hello world, is not a benchmark suite, and apps like uWSGI will always \"cheat\" as they are coded in C and uses custom protocols :) Gunicorn can be configured in no time, uWSGI has tons of unique features for production apps, mod_wsgi is rock-solid and fully integrated in apache, and so on ... If we push users to look only at speed test, we will ends up with sync app running on async servers.... oops this is already happening :)", "group_id": 292, "id": 873933}, {"user_id": 7, "stars": [], "topic_id": 32965, "date_created": 1304231665.8954389, "message": "it's akin to benchmarking GCC by putting 3 second sleeps in your benchmark", "group_id": 292, "id": 874058}, {"user_id": 7, "stars": [], "topic_id": 32965, "date_created": 1304231654.4015591, "message": "if you want to benchmark the sever it doesn't make sense to introduce a high latency app IMO", "group_id": 292, "id": 874057}, {"user_id": 7, "stars": [], "topic_id": 32965, "date_created": 1304231677.535934, "message": "OTOH it takes a realtziation by the reader that your app code does exist", "group_id": 292, "id": 874059}, {"user_id": 7, "stars": [], "topic_id": 32965, "date_created": 1304231687.7153299, "message": "and that none of this matters work a damn to 99.999999% of people", "group_id": 292, "id": 874060}, {"user_id": 6671, "stars": [], "topic_id": 32965, "date_created": 1304233280.6642759, "message": "@rob17 It would be nice if somebody made a reasonable WSGI benchmark, though, instead of everyone doing trivial hello-world benchmarks.", "group_id": 292, "id": 874084}, {"user_id": 4383, "stars": [], "topic_id": 32965, "date_created": 1304234639.913089, "message": "I think that meinheld is only really useful as a faster alternative to the default gunicorn worker. It's basically for when you have already decided on or are already using gunicorn.", "group_id": 292, "id": 874116}, {"user_id": 12404, "stars": [], "topic_id": 32965, "date_created": 1304293161.103049, "message": "this will be awesome if ever the webserver becomes the long pull in any moderately complex application. :)", "group_id": 292, "id": 878804}, {"user_id": 9128, "stars": [], "topic_id": 32965, "date_created": 1322228062.2015271, "message": "Is there any way that async workers can mitigate things like slow queries? So the async worker realises it's waiting and so deals with another request while the query blocks?", "group_id": 292, "id": 2636981}]