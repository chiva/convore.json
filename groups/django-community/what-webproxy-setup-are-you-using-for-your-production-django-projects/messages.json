[{"user_id": 7378, "stars": [], "topic_id": 5074, "date_created": 1297648688.9951761, "message": "Nginx + apache mod_wsgi for the site and wsgi services... though we're considering moving the services to nginx + gunicorn. We have a cluster of 4 web servers with a 2 load balancers in front sending requests to nginx which passes it on to apache.", "group_id": 81, "id": 95382}, {"user_id": 9307, "stars": [], "topic_id": 5074, "date_created": 1297650586.5140941, "message": "I like nginx + gunicorn.  Enough so that I made a Fabric wrapper for configuring them together. See http://pypi.python.org/pypi/silk-deployment/", "group_id": 81, "id": 95568}, {"user_id": 8740, "stars": [{"date_created": 1297710259.5711269, "user_id": 177}], "topic_id": 5074, "date_created": 1297678578.869905, "message": "We run everything on ep.io through HaProxy + Nginx + gunicorn, and it seems to be working quite well so far. Note that the async gunicorn workers are slightly slower than sync unless you actually use async calls.", "group_id": 81, "id": 97621}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297684931.879045, "message": "(and that's with gunicorn for the Django and Flask sites...)", "group_id": 81, "id": 98415}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297684903.028162, "message": "I've been moving all our sites to a purely apache-free stack. I've even got our few PHP sites (including a couple WordPress blogs) running on nginx using fcgi for PHP with supervisor. It's thus far proven a lot more stable than our previous stack with apache.", "group_id": 81, "id": 98404}, {"user_id": 9013, "stars": [], "topic_id": 5074, "date_created": 1297689130.0489719, "message": "nginx + gunicorn", "group_id": 81, "id": 99101}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297690062.136148, "message": "@Samuirai I think the biggest advantage is being able to isolate your individual sites. Instead of an `apache2ctl graceful` that reloads ALL of your sites just to effect the changes made to one, you can use `supervisorctl restart some-specific-site` and not affect your other running sites at all.", "group_id": 81, "id": 99197}, {"user_id": 10074, "stars": [], "topic_id": 5074, "date_created": 1297689746.5868671, "message": "I just set up an apache server to run my django projects. Would you give me the advice to redo it with gunicorn? What are the benefits. I just develop in a private environment.", "group_id": 81, "id": 99175}, {"user_id": 7376, "stars": [], "topic_id": 5074, "date_created": 1297694033.304493, "message": "@rlofthouse try nginx + uwsgi before you try gunicorn.", "group_id": 81, "id": 100049}, {"user_id": 218, "stars": [], "topic_id": 5074, "date_created": 1297699192.6664009, "message": "I'm using nginx + gunicorn fronted by Varnish.", "group_id": 81, "id": 100951}, {"user_id": 214, "stars": [], "topic_id": 5074, "date_created": 1297712904.5800059, "message": "So, this'll probably sound stupid (and when it comes to haproxy, I am), but... what value does haproxy sitting in front of nginx provide? What can it do that nginx can't?", "group_id": 81, "id": 103999}, {"user_id": 7, "stars": [], "topic_id": 5074, "date_created": 1297712929.104003, "message": "ignorance is not stupidity", "group_id": 81, "id": 104004}, {"user_id": 177, "stars": [], "topic_id": 5074, "date_created": 1297710354.6163731, "message": "Been using nginx + gunicorn and just added haproxy. Using sync workers right now, but I'd definitely like to know where I can find some resources about using the async calls.", "group_id": 81, "id": 103414}, {"user_id": 214, "stars": [], "topic_id": 5074, "date_created": 1297713193.8990469, "message": "Ok, semantic nit-picking accepted ;-)", "group_id": 81, "id": 104044}, {"user_id": 603, "stars": [{"date_created": 1297716497.584291, "user_id": 177}, {"date_created": 1303202235.0820761, "user_id": 8}], "topic_id": 5074, "date_created": 1297714912.1455979, "message": "it's been a while, but I've used haproxy to do both round-robin and sticky session proxing. Usually I have haproxy in front of several nginx instances, which then proxy to gunicorn listening on a domain socket", "group_id": 81, "id": 104303}, {"user_id": 177, "stars": [], "topic_id": 5074, "date_created": 1297716519.009119, "message": "@mattg Thanks for the heads up on the domain socket... never really took the time to investigate that before.", "group_id": 81, "id": 104758}, {"user_id": 603, "stars": [], "topic_id": 5074, "date_created": 1297717620.009829, "message": "@bryan no problem, i believe it's slightly faster than using a tcp socket.", "group_id": 81, "id": 105178}, {"user_id": 177, "stars": [], "topic_id": 5074, "date_created": 1297717650.139909, "message": "@mattg Makes sense. Then I found this: http://macournoyer.wordpress.com/2008/01/26/get-intimate-with-your-load-balancer-tonight/ which seemed to say the same.", "group_id": 81, "id": 105192}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297718496.085, "message": "@statico I haven't had a whole lot of chances to use it yet, but I think it's pretty awesome.", "group_id": 81, "id": 105575}, {"user_id": 4520, "stars": [], "topic_id": 5074, "date_created": 1297718293.706841, "message": "@joshourisman I'm glad someone else has discovered Flask :)", "group_id": 81, "id": 105486}, {"user_id": 11358, "stars": [], "topic_id": 5074, "date_created": 1297763195.317255, "message": "is it possible to do so?", "group_id": 81, "id": 110030}, {"user_id": 11358, "stars": [], "topic_id": 5074, "date_created": 1297763188.143399, "message": "where can I find out more about nginx internals? I want to use it as an HTTP request queue. So I have apache sitting as the main web server, and I want nginx to not pass it more than X simultaneous requests.", "group_id": 81, "id": 110026}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297771192.1886201, "message": "@dhruvbird but why even bother with Apache? What are you doing with it that you can't do with nginx?", "group_id": 81, "id": 110479}, {"user_id": 2024, "stars": [], "topic_id": 5074, "date_created": 1297771175.1558571, "message": "@dhruvbird the nginx wiki is pretty exhaustive, though it's not always that easy to find what you're looking for. http://wiki.nginx.org/Main", "group_id": 81, "id": 110476}, {"user_id": 11421, "stars": [], "topic_id": 5074, "date_created": 1297772400.2907181, "message": "nginx + flup (fastcgi). Same nginx instance also serves the site's static media/uploads.", "group_id": 81, "id": 110619}, {"user_id": 9650, "stars": [], "topic_id": 5074, "date_created": 1297799528.6777101, "message": "Lighty for the static files and load balancing, and Apache+mod_wsgi for the main work.  But I think in most cases it doesn't really matter anyway.", "group_id": 81, "id": 114255}, {"user_id": 281, "stars": [], "topic_id": 5074, "date_created": 1297798616.124877, "message": "We're running nginx+gunicorn behind Amazon's Elastic Load Balancer service", "group_id": 81, "id": 114120}, {"user_id": 7378, "stars": [], "topic_id": 5074, "date_created": 1297802793.364471, "message": "@ericmoritz too late, we're already going with gunicorn :)", "group_id": 81, "id": 114881}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297806900.007237, "message": "that may actually be 0.8.4+", "group_id": 81, "id": 115797}, {"user_id": 603, "stars": [], "topic_id": 5074, "date_created": 1297805454.150115, "message": "@ericmoritz do you still have to compile nginx with uwsgi support?", "group_id": 81, "id": 115440}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297806907.7233641, "message": "haproxy->nginx->mod_wsgi", "group_id": 81, "id": 115800}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297806884.495368, "message": "@mattg as of nginx 0.8.x, no", "group_id": 81, "id": 115793}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297806918.286942, "message": "we're going to put one or two web boxes on uwsgi sometime in march and see how it handles", "group_id": 81, "id": 115803}, {"user_id": 603, "stars": [], "topic_id": 5074, "date_created": 1297807208.66717, "message": "i didn't know that nginx will handle apache modules", "group_id": 81, "id": 115860}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297811479.488987, "message": "mod_wsgi is short hand meaning apache running mod_wsgu", "group_id": 81, "id": 116601}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297811503.4921341, "message": "graham templeton has a write up somewhere why so", "group_id": 81, "id": 116605}, {"user_id": 3880, "stars": [], "topic_id": 5074, "date_created": 1297809728.1525221, "message": "@mattg there's mod_wsgi for nginx  (http://wiki.nginx.org/NgxWSGIModule)", "group_id": 81, "id": 116283}, {"user_id": 228, "stars": [], "topic_id": 5074, "date_created": 1297811490.032752, "message": "using the mod_wsgi module for nginx is a quick way to be doing it wrong", "group_id": 81, "id": 116603}, {"user_id": 7378, "stars": [{"date_created": 1297831414.3589759, "user_id": 3705}], "topic_id": 5074, "date_created": 1297811953.1597681, "message": "http://blog.dscpl.com.au/2009/05/blocking-requests-and-nginx-version-of.html <", "group_id": 81, "id": 116660}, {"user_id": 7376, "stars": [], "topic_id": 5074, "date_created": 1297896114.812283, "message": "@mattg no the newer versions of nginx have a uwsgi module built in", "group_id": 81, "id": 125771}, {"user_id": 6704, "stars": [], "topic_id": 5074, "date_created": 1307025669.8253901, "message": "@carljm HAProxy is reputed to be better at detecting which servers behind it are up and which are down \u2014 while nginx can load-balance between backends, it might not behave as cleanly if one of them goes down.", "group_id": 81, "id": 1267572}]